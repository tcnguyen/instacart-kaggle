{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author : Trong Canh Nguyen\n",
    "\n",
    "# This script considers all the products a user has ordered\n",
    "#\n",
    "# We train a model computing the probability of reorder on the \"train\" data\n",
    "#\n",
    "# For the submission, we keep the orders that have a probability of\n",
    "# reorder higher than a threshold\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "IDIR = '../input/'\n",
    "FEATURES_PATH = './features3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(FEATURES_PATH + \"data.csv\", dtype= dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf(FEATURES_PATH + \"data.h5\", \"data\")\n",
    "data.reset_index(inplace=True)\n",
    "print(\"memory = \", data.memory_usage().sum()/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [    \n",
    "    'up_orders',\n",
    "    'up_add_to_cart_order_mean',\n",
    "    'up_order_rate',\n",
    "    'up_order_rate_since_first_order',\n",
    "    'up_orders_since_last_order',\n",
    "    'up_days_since_last_order',\n",
    "    'up_in_same_day_previous_order',\n",
    "    \n",
    "    'user_total_order',\n",
    "    'user_order_size_mean',\n",
    "    'user_reorder_rate',\n",
    "    'user_days_since_last_order',   \n",
    "    \n",
    "    'product_reorder_ratio',   \n",
    "    \n",
    "    'aisle_reorder_ratio',\n",
    "    'user_aisle_reordered_ratio',    \n",
    "    'dep_reorder_ratio',\n",
    "    'user_dep_reordered_ratio'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_features = data[data.user_eval_set == \"train\"][['user_id', 'product_id']+ features + [\"up_reordered\"]]\n",
    "\n",
    "tmp = data_features.user_id.unique()\n",
    "user_train = tmp[0:120000]\n",
    "user_valid = tmp[120000:]\n",
    "\n",
    "data_train = data_features[data_features.user_id.isin(user_train)]\n",
    "data_valid = data_features[data_features.user_id.isin(user_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train.to_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_train\", mode=\"a\")\n",
    "data_valid.to_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_valid\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = data[data.user_eval_set == \"test\"][['user_id', 'product_id']+ features]\n",
    "data_test.to_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_test\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data_train, data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_train\")\n",
    "data_valid = pd.read_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(data_train))\n",
    "print(len(data_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train= data_train[features]\n",
    "y_train= data_train['up_reordered']\n",
    "X_valid= data_valid[features]\n",
    "y_valid= data_valid['up_reordered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('formating for lgb')\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_valid = lgb.Dataset(X_valid, label=y_valid, reference=d_train)\n",
    "#d_train.save_binary(FEATURES_PATH +  'train.bin')\n",
    "#d_valid.save_binary(FEATURES_PATH +  'valid.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 200,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params, d_train, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.save_model(FEATURES_PATH+ 'trained_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst.add_valid(d_valid, \"valid1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst.eval_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst.eval_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y, y_, correct):\n",
    "    if y_>0:\n",
    "        return correct/y_\n",
    "    else:\n",
    "        return 1.0\n",
    "        \n",
    "def recall(y, y_, correct):\n",
    "    if y>0:\n",
    "        return correct/y\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def f1(y,y_, correct):\n",
    "    p = precision(y, y_, correct)\n",
    "    r = recall(y, y_, correct)\n",
    "    if (p == 0) and (r ==0):\n",
    "        return 0.\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    return f1\n",
    "\n",
    "def compute_f1(valid_df, threshold):\n",
    "    valid_df['y_'] = valid_df['pred'] > threshold\n",
    "    valid_df['correct'] = (valid_df['y'] == valid_df['y_']) & (valid_df['y_'])\n",
    "    result = valid_df.groupby('user_id').sum()\n",
    "    result['f1'] = result.apply(lambda row: f1(row['y'], row['y_'], row['correct']), axis=1)\n",
    "    return result['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_valid = bst.predict(X_valid)\n",
    "pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df = data_valid[['user_id', 'product_id']].copy()\n",
    "valid_df[\"y\"] = y_valid\n",
    "valid_df[\"pred\"] = pred_valid\n",
    "valid_df[\"y_\"] = valid_df[\"pred\"]  >= 0.20\n",
    "valid_df['correct'] = (valid_df['y'] == valid_df['y_']) & (valid_df['y_'])\n",
    "valid_df.sort_values(['user_id', 'pred'], ascending=[True, False], inplace = True)\n",
    "#print(\"valid log loss = \", -((valid_df[\"y\"]*np.log(valid_df[\"pred\"])+ (1.-valid_df[\"y\"])* np.log(1.- valid_df[\"pred\"]))).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = valid_df.groupby('user_id').sum()\n",
    "result['f1'] = result.apply(lambda row: f1(row['y'], row['y_'], row['correct']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result[result.y_ == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_f1(valid_df, 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = lgb.Booster(model_file=FEATURES_PATH+ 'trained_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('light GBM predict')\n",
    "pred_test = bst.predict(data_test[features])\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = pd.read_csv(IDIR + 'orders.csv', dtype={\n",
    "        'order_id': np.int32,\n",
    "        'user_id': np.int32},\n",
    "        usecols=[\"order_id\", \"user_id\", \"eval_set\"])\n",
    "\n",
    "test_orders= orders[orders.eval_set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame()\n",
    "prediction[['user_id', 'product_id']] = data_test[['user_id', 'product_id']]\n",
    "prediction['proba'] = pred_test\n",
    "prediction.sort_values(by=['user_id', 'proba'], ascending=[True, False], inplace=True)\n",
    "prediction = pd.merge(prediction, test_orders[['order_id', 'user_id']], on=\"user_id\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(bst, max_num_features=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.20\n",
    "recommend = prediction[prediction.proba >= threshold].groupby('order_id').product_id.apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df = pd.DataFrame()\n",
    "recommend_df[\"count\"] = prediction.groupby('order_id').size()\n",
    "recommend_df['product_list'] = recommend\n",
    "recommend_df['products']= recommend_df.product_list.apply(lambda p: ' '.join([str(x)  for x in p]) if type(p) == list else 'None' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df['products'].to_csv(FEATURES_PATH +  'lgb/recommend.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using average user basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = []\n",
    "count = 0\n",
    "for _,row in test_orders[['user_id', 'order_id']].iterrows():\n",
    "    count += 1\n",
    "    if (count)%10000 == 0:\n",
    "        print(count)    \n",
    "    \n",
    "    user_id, order_id = row['user_id'], row['order_id']\n",
    "    n = int(user_basket_avg.ix[user_id].basket_size_avg)+1\n",
    "    products.append(list(prediction[prediction.user_id == user_id].product_id[:n]))\n",
    "    \n",
    "# create submission\n",
    "submission = pd.DataFrame()\n",
    "submission['order_id'] = test_orders['order_id']\n",
    "submission['products'] = [' '.join([str(x) for x in p]) for p in products]\n",
    "submission.sort_values(by='order_id', inplace = True)\n",
    "submission.to_csv(FEATURES_PATH + 'submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
