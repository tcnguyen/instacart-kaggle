{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author : Trong Canh Nguyen\n",
    "\n",
    "# This script considers all the products a user has ordered\n",
    "#\n",
    "# We train a model computing the probability of reorder on the \"train\" data\n",
    "#\n",
    "# For the submission, we keep the orders that have a probability of\n",
    "# reorder higher than a threshold\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from helper import *\n",
    "IDIR = '../input/'\n",
    "FEATURES_PATH = './features3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(FEATURES_PATH + \"data.csv\", dtype= dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf(FEATURES_PATH + \"data.h5\", \"data\")\n",
    "data.reset_index(inplace=True)\n",
    "print(\"memory = \", data.memory_usage().sum()/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = list(data.columns)\n",
    "not_features = ['user_id', 'product_id', 'aisle_id',  'user_eval_set', 'up_reordered']\n",
    "features = list(set(columns) - set(not_features))\n",
    "print(\"number of features\", len(features))\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_embedding = pd.read_csv(IDIR+\"product_embeddings.csv\")\n",
    "product_embedding.drop(['product_name','aisle_id','department_id'], axis = 1, inplace = True)\n",
    "columns_dict = dict([(str(i), 'pe_'+str(i)) for i in range(32)])\n",
    "product_embedding.rename(columns=columns_dict, inplace = True)\n",
    "pe_columns = ['pe_'+str(i) for i in range(32)]\n",
    "product_embedding[pe_columns] = product_embedding[pe_columns].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.merge(product_embedding, on=\"product_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"memory = \", data.memory_usage().sum()/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.set_index(['user_id', 'product_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_hdf(FEATURES_PATH + \"data_pe.h5\", \"data\", mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_features = data[data.user_eval_set == \"train\"][['user_id', 'product_id']+ features + [\"up_reordered\"]]\n",
    "data_features = data[data.user_eval_set == \"train\"]\n",
    "\n",
    "tmp = data_features.user_id.unique()\n",
    "user_train = tmp[0:120000]\n",
    "user_valid = tmp[120000:]\n",
    "\n",
    "data_train = data_features[data_features.user_id.isin(user_train)]\n",
    "data_valid = data_features[data_features.user_id.isin(user_valid)]\n",
    "print(len(data_train))\n",
    "print(len(data_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_features.to_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_features\", mode=\"a\")\n",
    "data_train.to_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_train\", mode=\"a\")\n",
    "data_valid.to_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_valid\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = data[data.user_eval_set == \"test\"]\n",
    "data_test.to_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_test\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data_train, data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "features = ['up_order_period',\n",
    " 'user_dep_ratio',\n",
    " 'up_order_rate',\n",
    " 'up_order_period_mean',\n",
    " 'order_hour_of_median',\n",
    " 'user_dep_reordered_ratio',\n",
    " 'up_first_order',\n",
    " 'user_aisle_reordered_ratio',\n",
    " 'aisle_reorder_ratio',\n",
    " 'up_last_order',\n",
    " 'add_to_cart_order_relative',\n",
    " 'up_orders_since_last_order',\n",
    " 'user_total_order',\n",
    " 'up_add_to_cart_order_mean',\n",
    " 'order_hour_of_day_mean',\n",
    " 'user_order_size_mean',\n",
    " 'user_order_hour_of_day_mean',\n",
    " 'is_organic',\n",
    " 'user_order_dow',\n",
    " 'user_reorder_rate',\n",
    " 'up_days_since_last_order',\n",
    " 'user_order_hour_of_day',\n",
    " 'product_reorder_probability',\n",
    " 'department_id',\n",
    " 'user_days_since_prior_mean',\n",
    " 'user_aisle_ratio',\n",
    " 'up_order_dow_median',\n",
    " 'product_reorder_ratio',\n",
    " 'up_orders',\n",
    " 'up_order_dow_mean',\n",
    " 'dep_reorder_ratio',\n",
    " 'add_to_cart_order_relative_median',\n",
    " 'up_days_since_prior_order_mean',\n",
    " 'user_order_dow_mean',\n",
    " 'up_recency',\n",
    " 'up_order_rate_since_first_order',\n",
    " 'user_days_since_prior_order']\n",
    "\n",
    "#features = features + pe_columns\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train len 7757907\n",
      "data_valid len 716754\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_train\")\n",
    "data_valid = pd.read_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_valid\")\n",
    "print(\"data_train len\", len(data_train))\n",
    "print(\"data_valid len\", len(data_valid))\n",
    "\n",
    "#columns = list(data_train.columns)\n",
    "#not_features = ['user_id', 'product_id', 'up_reordered']\n",
    "#features = list(set(columns) - set(not_features))\n",
    "#print(\"number of features\", len(features))\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_train = data_train.merge(product_embedding, on='product_id', how = 'left')\n",
    "#data_valid = data_valid.merge(product_embedding, on='product_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train= data_train[features].values\n",
    "y_train= data_train['up_reordered'].values\n",
    "X_valid= data_valid[features].values\n",
    "y_valid= data_valid['up_reordered'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_train\n",
    "del data_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "#with h5py.File(FEATURES_PATH+ 'data_train_product_embedding.h5', 'w') as hf:\n",
    "with h5py.File(FEATURES_PATH+ 'data_train.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"X_train\",  data=X_train)\n",
    "    hf.create_dataset(\"y_train\",  data=y_train)\n",
    "\n",
    "#with h5py.File(FEATURES_PATH+ 'data_train_product_embedding.h5', 'a') as hf:\n",
    "with h5py.File(FEATURES_PATH+ 'data_train.h5', 'a') as hf:\n",
    "    hf.create_dataset(\"X_valid\",  data=X_valid)\n",
    "    hf.create_dataset(\"y_valid\",  data=y_valid)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File(FEATURES_PATH+ 'data_train.h5', 'r') as hf:\n",
    "    X_train = hf['X_train'][:]\n",
    "    y_train = hf['y_train'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_train = 1 - (1- y_train)*0.8\n",
    "weight_valid = 1 - (1- y_valid)*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formating for lgb\n"
     ]
    }
   ],
   "source": [
    "print('formating for lgb')\n",
    "d_train = lgb.Dataset(X_train, label=y_train, feature_name = features, categorical_feature='department_id')\n",
    "d_valid = lgb.Dataset(X_valid, label=y_valid, feature_name = features, categorical_feature='department_id', reference=d_train)\n",
    "#d_train.save_binary(FEATURES_PATH +  'train.bin')\n",
    "#d_valid.save_binary(FEATURES_PATH +  'valid.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 512,\n",
    "    'max_depth': 12,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'feature_fraction': 0.7,\n",
    "    #'bagging_fraction': 0.95,\n",
    "    #'bagging_freq': 5,\n",
    "    'learning_rate':0.05\n",
    "}\n",
    "ROUNDS = 350\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params, d_train, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light GBM train :-)\n"
     ]
    }
   ],
   "source": [
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params, d_train, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.save_model(FEATURES_PATH + 'lgb/trained_model_37_features_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bst = lgb.Booster(model_file=FEATURES_PATH+ 'lgb/trained_model_28_features_categorical.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst.add_valid(d_valid, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('training', 'binary_logloss', 0.23381499168485428, False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.eval_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('valid', 'binary_logloss', 0.24296611589068384, False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.eval_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/canh/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_train = xgboost.DMatrix(X_train, y_train)\n",
    "xgb_params = {\n",
    "    \"objective\"         : \"reg:logistic\"\n",
    "    ,\"eval_metric\"      : \"logloss\"\n",
    "    ,\"eta\"              : 0.1\n",
    "    ,\"max_depth\"        : 6\n",
    "    ,\"min_child_weight\" :10\n",
    "    ,\"gamma\"            :0.70\n",
    "    ,\"subsample\"        :0.76\n",
    "    ,\"colsample_bytree\" :0.95\n",
    "    ,\"alpha\"            :2e-05\n",
    "    ,\"lambda\"           :10\n",
    "}\n",
    "\n",
    "watchlist= [(d_train, \"train\")]\n",
    "bst = xgboost.train(params=xgb_params, dtrain=d_train, num_boost_round=80, evals=watchlist, verbose_eval=10)\n",
    "xgboost.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = data_features[features]\n",
    "y_all = data_features['up_reordered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_all = lgb.Dataset(X_all, label=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('light GBM train :-)')\n",
    "bst_all = lgb.train(params, dataset_all, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst_all.save_model(FEATURES_PATH + 'lgb/trained_model_num_leaves500_ALL.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst_all.eval_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y, y_, correct, has_none=False):\n",
    "    if y_ > 0:\n",
    "        if not has_none:\n",
    "            return correct / y_\n",
    "        else:\n",
    "            if y > 0:\n",
    "                return correct / (y_ + 1)\n",
    "            else:\n",
    "                return 1. / (y_ + 1)\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def recall(y, y_, correct, has_none=False):\n",
    "    if y > 0:\n",
    "        return correct / y\n",
    "    else:\n",
    "        if has_none or (y_ == 0):\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.\n",
    "\n",
    "\n",
    "def f1(y, y_, correct, has_none=False):\n",
    "    p = precision(y, y_, correct, has_none)\n",
    "    r = recall(y, y_, correct, has_none)\n",
    "    if (p == 0) and (r == 0):\n",
    "        return 0.\n",
    "    f1 = 2 * p * r / (p + r)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def compute_f1(valid_df, threshold):\n",
    "    valid_df['y_'] = valid_df['pred'] > threshold\n",
    "    valid_df['correct'] = (valid_df['y'] == valid_df['y_']) & (valid_df['y_'])\n",
    "    result = valid_df.groupby('user_id').sum()\n",
    "    result['f1'] = result.apply(lambda row: f1(row['y'], row['y_'], row['correct']), axis=1)\n",
    "    return result['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bst = lgb.Booster(model_file=FEATURES_PATH+ 'lgb/trained_model_27_features_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04016588,  0.05939614,  0.06182783, ...,  0.1355507 ,\n",
       "        0.0247439 ,  0.12688935])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid = bst.predict(X_valid)\n",
    "pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df = data_valid[['user_id', 'product_id']].copy()\n",
    "valid_df[\"y\"] = y_valid\n",
    "valid_df[\"pred\"] = pred_valid\n",
    "valid_df[\"y_\"] = valid_df[\"pred\"]  >= 0.2\n",
    "valid_df['correct'] = (valid_df['y'] == valid_df['y_']) & (valid_df['y_'])\n",
    "valid_df.sort_values(['user_id', 'pred'], ascending=[True, False], inplace = True)\n",
    "#print(\"valid log loss = \", -((valid_df[\"y\"]*np.log(valid_df[\"pred\"])+ (1.-valid_df[\"y\"])* np.log(1.- valid_df[\"pred\"]))).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37876167530883526"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(valid_df, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = valid_df.groupby('user_id').sum()\n",
    "result['precision'] = result.apply(lambda row: precision(row['y'], row['y_'], row['correct']), axis=1)\n",
    "result['recall'] = result.apply(lambda row: recall(row['y'], row['y_'], row['correct']), axis=1)\n",
    "result['f1'] = result.apply(lambda row: f1(row['y'], row['y_'], row['correct']), axis=1)\n",
    "\n",
    "print(\"precision mean = \", result.precision.mean())\n",
    "print(\"recall mean = \", result.recall.mean())\n",
    "print(\"f1 mean = \", result.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#valid_df.to_csv(FEATURES_PATH+ \"valid_df.csv\")\n",
    "valid_df.to_hdf(FEATURES_PATH+ \"results.h5\", \"valid_df\", mode = \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bst_all = lgb.Booster(model_file=FEATURES_PATH+ 'trained_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_hdf(FEATURES_PATH + \"lgb_data.h5\", \"data_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('light GBM predict')\n",
    "pred_test = bst.predict(data_test[features])\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = pd.read_csv(IDIR + 'orders.csv', dtype={\n",
    "        'order_id': np.int32,\n",
    "        'user_id': np.int32},\n",
    "        usecols=[\"order_id\", \"user_id\", \"eval_set\"])\n",
    "\n",
    "test_orders= orders[orders.eval_set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame()\n",
    "prediction[['user_id', 'product_id']] = data_test[['user_id', 'product_id']]\n",
    "prediction['proba'] = pred_test\n",
    "prediction.sort_values(by=['user_id', 'proba'], ascending=[True, False], inplace=True)\n",
    "prediction = pd.merge(prediction, test_orders[['order_id', 'user_id']], on=\"user_id\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(bst, max_num_features=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.20\n",
    "recommend = prediction[prediction.proba >= threshold].groupby('order_id').product_id.apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_none_df = prediction[prediction.proba >= threshold].groupby('order_id').proba.agg([np.size, np.max])\n",
    "add_none_df['None'] = (add_none_df['size'] > 0) & (add_none_df['size'] < 4) & (add_none_df['amax'] < 0.46)\n",
    "add_none_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df = pd.DataFrame()\n",
    "recommend_df[\"count\"] = prediction.groupby('order_id').size()\n",
    "recommend_df['product_list'] = recommend\n",
    "recommend_df['none'] = add_none_df['None']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_prediction(row):\n",
    "    p = row.product_list\n",
    "    if type(p) == list:\n",
    "        result = ' '.join([str(x)  for x in p])\n",
    "        \n",
    "        if row.none:\n",
    "            result = 'None ' + result\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df['products']= recommend_df.apply(lambda row:  generate_prediction(row) , axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df['products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_df['products'].to_csv(FEATURES_PATH +  'lgb/recommend5_none.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using average user basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = []\n",
    "count = 0\n",
    "for _,row in test_orders[['user_id', 'order_id']].iterrows():\n",
    "    count += 1\n",
    "    if (count)%10000 == 0:\n",
    "        print(count)    \n",
    "    \n",
    "    user_id, order_id = row['user_id'], row['order_id']\n",
    "    n = int(user_basket_avg.ix[user_id].basket_size_avg)+1\n",
    "    products.append(list(prediction[prediction.user_id == user_id].product_id[:n]))\n",
    "    \n",
    "# create submission\n",
    "submission = pd.DataFrame()\n",
    "submission['order_id'] = test_orders['order_id']\n",
    "submission['products'] = [' '.join([str(x) for x in p]) for p in products]\n",
    "submission.sort_values(by='order_id', inplace = True)\n",
    "submission.to_csv(FEATURES_PATH + 'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_none_incorrect = tmp[(tmp.y == 0) &  (tmp.y_ > 0)].user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_df[valid_df.user_id.isin(users_none_incorrect) & valid_df.y_].pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df[valid_df.y_].pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"None predicted correctly = \", len(tmp[(tmp.y == 0) &  (tmp.y_ == 0)]) / len(tmp[tmp.y == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"precision mean = \", result.precision.mean())\n",
    "print(\"recall mean = \", result.recall.mean())\n",
    "print(\"f1 mean = \", result.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = 0.3934358303379222\n",
    "r = 0.5387833182445639\n",
    "2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Not None but predict None = \", len(tmp[(tmp.y > 0) &  (tmp.y_ == 0)]) / len(tmp[tmp.y > 0]))\n",
    "print(\"None but predicted not None = \", len(tmp[(tmp.y == 0) &  (tmp.y_ > 0)]) / len(tmp[tmp.y == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_valid_not_reorder = tmp[(tmp.y == 0)].reset_index().user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_valid_user_not_reorder = data_valid[data_valid.user_id.isin(users_valid_not_reorder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_valid_user_not_reorder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_info = pd.read_hdf(FEATURES_PATH + \"features.h5\", \"user_info\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_info_user_not_reorder = user_info[user_info.user_id.isin(users_valid_not_reorder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_info_user_not_reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trains = pd.read_hdf(IDIR + \"input.h5\", \"trains\")\n",
    "trains = trains.merge(orders, on= \"order_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trains[trains.user_id == 188603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df[valid_df.user_id == 188603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(p,q):\n",
    "    return 2*p*q/(p+q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1_score(1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp[tmp.y == 0].y_.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When there is None, we predict on average 2.8542780748663104 products ==> can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df = data_valid[['user_id', 'product_id']].copy()\n",
    "valid_df[\"y\"] = y_valid\n",
    "valid_df[\"pred\"] = pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df[\"y_\"] = valid_df[\"pred\"]  >= 0.2\n",
    "valid_df['correct'] = (valid_df['y'] == valid_df['y_']) & (valid_df['y_'])\n",
    "valid_df.sort_values(['user_id', 'pred'], ascending=[True, False], inplace = True)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38652892812353923\n"
     ]
    }
   ],
   "source": [
    "threshold_none = 0.45\n",
    "result = valid_df.groupby('user_id').agg({'y':np.sum,'y_':np.sum, 'correct':np.sum, 'pred':np.max}).reset_index()\n",
    "result['None'] = (result['y_'] > 0) & (result['y_'] < 4) &(result['pred'] < threshold_none)\n",
    "result['precision'] = result.apply(lambda row: precision(row['y'], row['y_'], row['correct'], row['None']), axis=1)\n",
    "result['recall'] = result.apply(lambda row: recall(row['y'], row['y_'], row['correct'], row['None']), axis=1)\n",
    "result['f1'] = result.apply(lambda row: f1(row['y'], row['y_'], row['correct'], row['None']), axis=1)\n",
    "print(result.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rsult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-573ea53714c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrsult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rsult' is not defined"
     ]
    }
   ],
   "source": [
    "rsult.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_valid = data_valid.merge(result, on=['user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     403\n",
       "1.0     361\n",
       "2.0     307\n",
       "3.0     224\n",
       "4.0     144\n",
       "5.0      97\n",
       "6.0      65\n",
       "7.0      46\n",
       "8.0      38\n",
       "10.0     33\n",
       "9.0      20\n",
       "14.0     10\n",
       "13.0      9\n",
       "12.0      9\n",
       "11.0      8\n",
       "16.0      7\n",
       "15.0      7\n",
       "21.0      4\n",
       "20.0      3\n",
       "30.0      1\n",
       "34.0      1\n",
       "24.0      1\n",
       "18.0      1\n",
       "17.0      1\n",
       "19.0      1\n",
       "Name: y_, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[(result.y > 0) & (result.correct == 0)].y_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11209"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[(result.y > 0) & (result.y_ == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df.set_index(['user_id', 'product_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_valid.set_index(['user_id', 'product_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['up_order_dow_mean', 'up_order_dow_median', 'order_hour_of_day_mean',\n",
       "       'order_hour_of_median', 'add_to_cart_order_relative',\n",
       "       'add_to_cart_order_relative_median', 'up_orders', 'up_first_order',\n",
       "       'up_last_order', 'up_order_rate', 'up_orders_since_last_order',\n",
       "       'up_order_rate_since_first_order', 'up_days_since_last_order',\n",
       "       'up_order_period', 'up_order_period_mean',\n",
       "       'up_days_since_prior_order_mean', 'up_add_to_cart_order_mean',\n",
       "       'up_reordered', 'user_total_order', 'user_reorder_rate',\n",
       "       'user_order_size_mean', 'user_days_since_prior_mean', 'user_order_dow',\n",
       "       'user_order_hour_of_day', 'user_eval_set',\n",
       "       'user_days_since_prior_order', 'user_order_dow_mean',\n",
       "       'user_order_hour_of_day_mean', 'product_reorder_ratio', 'aisle_id',\n",
       "       'department_id', 'product_reorder_probability', 'is_organic',\n",
       "       'aisle_reorder_ratio', 'dep_reorder_ratio',\n",
       "       'user_aisle_reordered_ratio', 'user_aisle_ratio',\n",
       "       'user_dep_reordered_ratio', 'user_dep_ratio', 'up_recency', 'y', 'y_',\n",
       "       'correct', 'pred', 'None', 'precision', 'recall', 'f1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_df['mean_reorder_size'] = data_valid['user_reorder_rate']*data_valid['user_order_size_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "      <th>y_</th>\n",
       "      <th>correct</th>\n",
       "      <th>mean_reorder_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">188560</th>\n",
       "      <th>46676</th>\n",
       "      <td>0</td>\n",
       "      <td>0.230936</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35140</th>\n",
       "      <td>0</td>\n",
       "      <td>0.132307</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12932</th>\n",
       "      <td>0</td>\n",
       "      <td>0.128439</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27104</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116702</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33120</th>\n",
       "      <td>0</td>\n",
       "      <td>0.112261</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    y      pred     y_  correct  mean_reorder_size\n",
       "user_id product_id                                                \n",
       "188560  46676       0  0.230936   True    False               0.75\n",
       "        35140       0  0.132307  False    False               0.75\n",
       "        12932       0  0.128439  False    False               0.75\n",
       "        27104       0  0.116702  False    False               0.75\n",
       "        33120       0  0.112261  False    False               0.75"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "beta = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_f1_bis(valid_df, alpha, beta_low, beta_high):\n",
    "    valid_df['y_'] = (valid_df['mean_reorder_size'] < alpha) & (valid_df['pred'] > beta_low) | (valid_df['mean_reorder_size'] >= alpha) & (valid_df['pred'] > beta_high) \n",
    "    valid_df['correct'] = (valid_df['y'] == valid_df['y_']) & (valid_df['y_'])\n",
    "    result = valid_df.groupby('user_id').sum()\n",
    "    result['f1'] = result.apply(lambda row: f1(row['y'], row['y_'], row['correct']), axis=1)\n",
    "    return result['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37876167530883526"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1_bis(valid_df, 0.0, 0.05, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37881612759673244"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1_bis(valid_df, 0.0001, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = bst.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "      <th>y_</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>0.891531</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853975</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837507</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>25133</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774875</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>46149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735626</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  product_id  y      pred    y_  correct\n",
       "0         1         196  1  0.891531  True     True\n",
       "3         1       12427  0  0.853975  True    False\n",
       "1         1       10258  1  0.837507  True     True\n",
       "8         1       25133  1  0.774875  True     True\n",
       "16        1       46149  1  0.735626  True     True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data_train[['user_id', 'product_id']].copy()\n",
    "train_df[\"y\"] = y_train\n",
    "train_df[\"pred\"] = pred_train\n",
    "train_df[\"y_\"] = train_df[\"pred\"]  >= 0.2\n",
    "train_df['correct'] = (train_df['y'] == train_df['y_']) & (train_df['y_'])\n",
    "train_df.sort_values(['user_id', 'pred'], ascending=[True, False], inplace = True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4077120668767288\n"
     ]
    }
   ],
   "source": [
    "threshold_none = 0.45\n",
    "result_train = train_df.groupby('user_id').agg({'y':np.sum,'y_':np.sum, 'correct':np.sum, 'pred':np.max}).reset_index()\n",
    "result_train['None'] = (result_train['y_'] > 0) & (result_train['y_'] < 4) &(result_train['pred'] < threshold_none)\n",
    "result_train['precision'] = result_train.apply(lambda row: precision(row['y'], row['y_'], row['correct'], row['None']), axis=1)\n",
    "result_train['recall'] = result_train.apply(lambda row: recall(row['y'], row['y_'], row['correct'], row['None']), axis=1)\n",
    "result_train['f1'] = result_train.apply(lambda row: f1(row['y'], row['y_'], row['correct'], row['None']), axis=1)\n",
    "print(result_train.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "false_user_id = result_train[result_train.f1 == 0].reset_index().user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_train.to_hdf(FEATURES_PATH+\"save.h5\", \"result_train\")\n",
    "train_df.to_hdf(FEATURES_PATH+\"save.h5\", \"train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_data_train = data_train[data_train.user_id.isin(false_user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_data_train.to_hdf(FEATURES_PATH+\"save.h5\", \"false_data_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198272"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(false_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_false_train = false_data_train[features].values\n",
    "y_false_train = false_data_train['up_reordered'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_false_train = lgb.Dataset(X_false_train, label=y_false_train, feature_name = features, categorical_feature='department_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light GBM train :-)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 12,\n",
    "    'min_data_in_leaf':100,\n",
    "    'feature_fraction': 0.7,\n",
    "    #'bagging_fraction': 0.95,\n",
    "    #'bagging_freq': 5,\n",
    "    'learning_rate':0.05\n",
    "}\n",
    "ROUNDS = 100\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst2 = lgb.train(params, d_false_train, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_valid_false = bst2.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716754"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_valid_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df = data_valid.reset_index()[['user_id', 'product_id']].copy()\n",
    "valid_df[\"y\"] = y_valid\n",
    "valid_df[\"pred\"] = pred_valid_total\n",
    "valid_df[\"y_\"] = valid_df[\"pred\"]  >= 0.2\n",
    "valid_df['correct'] = (valid_df['y'] == valid_df['y_']) & (valid_df['y_'])\n",
    "#valid_df.sort_values(['user_id', 'pred'], ascending=[True, False], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = 0.2\n",
    "pred_valid_total = (1-theta)*pred_valid + theta*pred_valid_false\n",
    "valid_df[\"pred\"] = pred_valid_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3744995492294094"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(valid_df, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
